# 项目描述
该项目结合了大语言模型 DeepSeek系列和开源的 LangGraph 框架，提供了一个端到端的示例应用，展示如何构建一个研究增强型的对话式 AI 系统。简单来说，这个项目的后端借助 LangGraph 编排的智能 Agent，能够对用户查询执行深度资料检索：自动生成搜索关键词、使用 tavily 搜索获取资料、分析结果找出知识空白，并不断迭代检索，直到形成有依据的答案并给出引用来源。前端则提供了一个 React 网页界面，允许用户方便地与 Agent 进行对话交互。
## 🌟 特性
项目核心是一套自动化深度搜索与问答功能，旨在解决“如何让对话式AI给出有依据的深入回答”这一问题。它主要体现为一个多步骤的“研究型 Agent”，可以将用户的提问转化为搜索行动，并经过一系列推理最终返回答案。项目的主要功能和特点包括：
- **动态查询生成**：Agent基于用户的问题，利用 LLM 理解意图并生成初步的搜索关键词或查询语句。这种动态查询能够针对输入问题的细微差异调整搜索方向，而非固定模板查询。
- **网络资料检索**：Agent 与网络搜索服务集成，通过Search API 获取相关网页内容。每个由 LLM 提出的查询都会触发一次网络检索，汇集潜在有用的网页及摘要信息，确保 Agent 拥有新鲜的外部知识。
- **反思与知识空白分析**：Agent 并非简单汇总搜索结果，而是会调用 LLM 对获取的信息进行反思性分析。具体来说，它检查当前资料是否足以完整回答问题，是否存在尚未覆盖的知识点或疑问（即“知识空白”）。这一步骤相当关键，提升了 Agent 从“信息罗列”到主动发现不足的能力。
- **迭代搜索完善**：如果通过反思发现信息不充分，Agent 将针对缺口迭代改进搜索。它会让 LLM 生成新的、更有针对性的搜索查询，然后再次检索网络并分析结果。这样的循环可持续进行多轮（项目中有配置最大循环次数），直到 Agent 认为信息足够支撑答案为止。这种循环机制赋予了 Agent **深入研究（Deep Research**的能力，类似人类研究者不断追问、查证直至弄清问题。
- **基于证据的回答生成**：在收集到充分资料后，Agent 使用 LLM对所有信息进行整合，生成完整回答。生成时特别注重引用来源：答案中会标注引用的文献或网页出处。最终给出的答复不仅有内容，而且附带来源引用，以确保答案的可追溯性和可信度。
## 🚀 快速开始
### 1. 克隆仓库
```bash
git clone https://github.com/spongebob26/mydeepsearch_fullstack.git
cd mydeepsearch_fullstack
```
### 2. 安装依赖
```bash
# 安装Python依赖
cd backend
pip install .
pip install -U "langgraph-cli[inmem]"

# 可重新打开新的终端，从主路径下进入指定目录，安装前端依赖
cd frontend
npm install
cd ..
```
### 3. 配置环境
复制配置模板并填入您的API密钥：
```bash
cp .env.example .env
```

### 4. 启动服务
```bash
# 在前后端目录下分别启动前后端服务，文件路径对照步骤2
# 通过运行以下命令本地启动 LangSmith 追踪
# 这将在 LangGraph Studio 中启用追踪可视化，并将您的追踪发送到 LangSmith 进行监控和分析。
langgraph dev

# 启动web端服务
npm run dev
```
## 📍 访问地址
- **前端应用**: http://localhost:5173/app/
- **API**: http://127.0.0.1:2024
- **Studio UI**: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
- **API 文档**: http://127.0.0.1:2024/docs
## 🏗️ 架构说明
- 采用了前后端解耦的全栈架构：前端是基于 React+Vite 构建的单页应用，提供用户友好的聊天界面，配以 Tailwind CSS 和 Shadcn UI 组件库美化界面。后端是基于 FastAPI 的服务，承载 LangGraph 智能体逻辑和 API 接口。这种架构清晰划分了界面展示和AI推理两个层面，便于分别开发和调试。
- 该项目可以看作是 LangGraph 框架的一个示范性应用（template 项目）。LangGraph 是 LangChain 团队推出的一个开源库，专门用于构建可控的多步骤 LLM 工作流。与传统顺序链式调用相比，LangGraph 引入“有状态图（stateful graph）”的概念，将复杂任务拆解为节点、并用图结构管理执行流程。开发者可以在 LangGraph 中定义节点（例如一次 LLM 推理或一个工具操作），以及状态在节点之间的传递方式，从而打造出具有决策分支和循环能力的智能体。 在本项目中，后端 Agent 就是基于 LangGraph 实现的。项目的 backend/ 目录下包含了 LangGraph Agent 的定义（主要逻辑在 backend/src/agent/graph.py）。可以说，LangGraph 提供了整个多步骤推理过程的“骨架”和运行时支持，而 LLM 则是完成每个节点任务的“大脑”。 具体而言，LangGraph 在该项目中扮演了以下角色：
  - 流程编排：利用 LangGraph，开发者以声明式方式定义了 Agent 的流程图。LangGraph 负责按照定义的图依次或迭代地调用各节点函数，确保流程正确执行和循环控制。这解决了手写复杂异步逻辑的困难，使多轮推理变得直观可维护
  - 状态管理：LangGraph 允许在节点之间传递状态数据。在本项目中，状态包括当前的搜索查询、累计的搜索结果列表、已发现的来源列表、迭代次数计数等。LangGraph 负责将这些数据在节点间合并和更新（例如把新搜索结果附加到总列表）。这保证了 Agent 每次迭代都能记忆之前步骤的信息，而不是无状态地重复工作。